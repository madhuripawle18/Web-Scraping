{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('.') \n",
    "import string\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "import nltk, re, pprint\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import request\n",
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the BeautifulSoup function we scrape the html page and store it as a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://playground.tensorflow.org/\"\n",
    "response = request.urlopen(url)\n",
    "html = response.read().decode('utf8')\n",
    "web_file = BeautifulSoup(html).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nA Neural Network Playground\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTinker With a Neural Network Right Here in Your Browser.Don’t Worry, You Can’t Break It. We Promise.\\n\\n\\n\\n\\n\\n\\nreplay\\n\\n\\nplay_arrow\\npause\\n\\n\\nskip_next\\n\\n\\n\\nEpoch\\n\\n\\n\\nLearning rate\\n\\n\\n0.00001\\n0.0001\\n0.001\\n0.003\\n0.01\\n0.03\\n0.1\\n0.3\\n1\\n3\\n10\\n\\n\\n\\n\\nActivation\\n\\n\\nReLU\\nTanh\\nSigmoid\\nLinear\\n\\n\\n\\n\\nRegularization\\n\\n\\nNone\\nL1\\nL2\\n\\n\\n\\n\\nRegularization rate\\n\\n\\n0\\n0.001\\n0.003\\n0.01\\n0.03\\n0.1\\n0.3\\n1\\n3\\n10\\n\\n\\n\\n\\nProblem type\\n\\n\\nClassification\\nRegression\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nData\\n\\n\\nWhich dataset do you want to use?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRatio of training to test data:\\xa0\\xa0XX%\\n\\n\\n\\n\\n\\nNoise:\\xa0\\xa0XX\\n\\n\\n\\n\\n\\nBatch size:\\xa0\\xa0XX\\n\\n\\n\\n\\n\\n            Regenerate\\n          \\n\\n\\n\\n\\nFeatures\\nWhich properties do you want to feed in?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nClick anywhere to edit.\\nWeight/Bias is 0.2.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            This is the output from one neuron. Hover to see it larger.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            The outputs are mixed with varying weights, shown by the thickness of the lines.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\nadd\\n\\n\\nremove\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOutput\\n\\n\\nTest loss\\n\\n\\n\\nTraining loss\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Colors shows data, neuron and weight values.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShow test data\\n\\n\\n\\nDiscretize output\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nkeyboard_arrow_down\\n\\n\\n\\n\\n\\nUm, What Is a Neural Network?\\nIt’s a technique for building a computer program that learns from data. It is based very loosely on how we think the human brain works. First, a collection of software “neurons” are created and connected together, allowing them to send messages to each other. Next, the network is asked to solve a problem, which it attempts to do over and over, each time strengthening the connections that lead to success and diminishing those that lead to failure. For a more detailed introduction to neural networks, Michael Nielsen’s Neural Networks and Deep Learning is a good place to start. For a more technical overview, try Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.\\n\\n\\nThis Is Cool, Can I Repurpose It?\\nPlease do! We’ve open sourced it on GitHub with the hope that it can make neural networks a little more accessible and easier to learn. You’re free to use it in any way that follows our Apache License. And if you have any suggestions for additions or changes, please let us know.\\nWe’ve also provided some controls below to enable you tailor the playground to a specific topic or lesson. Just choose which features you’d like to be visible below then save this link, or refresh the page.\\n\\n\\n\\nWhat Do All the Colors Mean?\\nOrange and blue are used throughout the visualization in slightly different ways, but in general orange shows negative values while blue shows positive values.\\nThe data points (represented by small circles) are initially colored orange or blue, which correspond to positive one and negative one.\\nIn the hidden layers, the lines are colored by the weights of the connections between neurons. Blue shows a positive weight, which means the network is using that output of the neuron as given. An orange line shows that the network is assiging a negative weight.\\nIn the output layer, the dots are colored orange or blue depending on their original values. The background color shows what the network is predicting for a particular area. The intensity of the color shows how confident that prediction is.\\n\\n\\nWhat Library Are You Using?\\nWe wrote a tiny neural network library\\n      that meets the demands of this educational visualization. For real-world applications, consider the\\n      TensorFlow library.\\n      \\n\\n\\nCredits\\n\\n        This was created by Daniel Smilkov and Shan Carter.\\n        This is a continuation of many people’s previous work — most notably Andrej Karpathy’s convnet.js demo\\n        and Chris Olah’s articles about neural networks.\\n        Many thanks also to D. Sculley for help with the original idea and to Fernanda Viégas and Martin Wattenberg and the rest of the\\n        Big Picture and Google Brain teams for feedback and guidance.\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSource on GitHub\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide the file into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_web = word_tokenize(web_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'Neural',\n",
       " 'Network',\n",
       " 'Playground',\n",
       " 'Tinker',\n",
       " 'With',\n",
       " 'a',\n",
       " 'Neural',\n",
       " 'Network',\n",
       " 'Right',\n",
       " 'Here',\n",
       " 'in',\n",
       " 'Your',\n",
       " 'Browser.Don',\n",
       " '’',\n",
       " 't',\n",
       " 'Worry',\n",
       " ',',\n",
       " 'You',\n",
       " 'Can',\n",
       " '’',\n",
       " 't',\n",
       " 'Break',\n",
       " 'It',\n",
       " '.',\n",
       " 'We',\n",
       " 'Promise',\n",
       " '.',\n",
       " 'replay',\n",
       " 'play_arrow',\n",
       " 'pause',\n",
       " 'skip_next',\n",
       " 'Epoch',\n",
       " 'Learning',\n",
       " 'rate',\n",
       " '0.00001',\n",
       " '0.0001',\n",
       " '0.001',\n",
       " '0.003',\n",
       " '0.01',\n",
       " '0.03',\n",
       " '0.1',\n",
       " '0.3',\n",
       " '1',\n",
       " '3',\n",
       " '10',\n",
       " 'Activation',\n",
       " 'ReLU',\n",
       " 'Tanh',\n",
       " 'Sigmoid',\n",
       " 'Linear',\n",
       " 'Regularization',\n",
       " 'None',\n",
       " 'L1',\n",
       " 'L2',\n",
       " 'Regularization',\n",
       " 'rate',\n",
       " '0',\n",
       " '0.001',\n",
       " '0.003',\n",
       " '0.01',\n",
       " '0.03',\n",
       " '0.1',\n",
       " '0.3',\n",
       " '1',\n",
       " '3',\n",
       " '10',\n",
       " 'Problem',\n",
       " 'type',\n",
       " 'Classification',\n",
       " 'Regression',\n",
       " 'Data',\n",
       " 'Which',\n",
       " 'dataset',\n",
       " 'do',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'use',\n",
       " '?',\n",
       " 'Ratio',\n",
       " 'of',\n",
       " 'training',\n",
       " 'to',\n",
       " 'test',\n",
       " 'data',\n",
       " ':',\n",
       " 'XX',\n",
       " '%',\n",
       " 'Noise',\n",
       " ':',\n",
       " 'XX',\n",
       " 'Batch',\n",
       " 'size',\n",
       " ':',\n",
       " 'XX',\n",
       " 'Regenerate',\n",
       " 'Features',\n",
       " 'Which',\n",
       " 'properties',\n",
       " 'do',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'feed',\n",
       " 'in',\n",
       " '?',\n",
       " 'Click',\n",
       " 'anywhere',\n",
       " 'to',\n",
       " 'edit',\n",
       " '.',\n",
       " 'Weight/Bias',\n",
       " 'is',\n",
       " '0.2',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'output',\n",
       " 'from',\n",
       " 'one',\n",
       " 'neuron',\n",
       " '.',\n",
       " 'Hover',\n",
       " 'to',\n",
       " 'see',\n",
       " 'it',\n",
       " 'larger',\n",
       " '.',\n",
       " 'The',\n",
       " 'outputs',\n",
       " 'are',\n",
       " 'mixed',\n",
       " 'with',\n",
       " 'varying',\n",
       " 'weights',\n",
       " ',',\n",
       " 'shown',\n",
       " 'by',\n",
       " 'the',\n",
       " 'thickness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lines',\n",
       " '.',\n",
       " 'add',\n",
       " 'remove',\n",
       " 'Output',\n",
       " 'Test',\n",
       " 'loss',\n",
       " 'Training',\n",
       " 'loss',\n",
       " 'Colors',\n",
       " 'shows',\n",
       " 'data',\n",
       " ',',\n",
       " 'neuron',\n",
       " 'and',\n",
       " 'weight',\n",
       " 'values',\n",
       " '.',\n",
       " 'Show',\n",
       " 'test',\n",
       " 'data',\n",
       " 'Discretize',\n",
       " 'output',\n",
       " 'keyboard_arrow_down',\n",
       " 'Um',\n",
       " ',',\n",
       " 'What',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'Neural',\n",
       " 'Network',\n",
       " '?',\n",
       " 'It',\n",
       " '’',\n",
       " 's',\n",
       " 'a',\n",
       " 'technique',\n",
       " 'for',\n",
       " 'building',\n",
       " 'a',\n",
       " 'computer',\n",
       " 'program',\n",
       " 'that',\n",
       " 'learns',\n",
       " 'from',\n",
       " 'data',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'based',\n",
       " 'very',\n",
       " 'loosely',\n",
       " 'on',\n",
       " 'how',\n",
       " 'we',\n",
       " 'think',\n",
       " 'the',\n",
       " 'human',\n",
       " 'brain',\n",
       " 'works',\n",
       " '.',\n",
       " 'First',\n",
       " ',',\n",
       " 'a',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'software',\n",
       " '“',\n",
       " 'neurons',\n",
       " '”',\n",
       " 'are',\n",
       " 'created',\n",
       " 'and',\n",
       " 'connected',\n",
       " 'together',\n",
       " ',',\n",
       " 'allowing',\n",
       " 'them',\n",
       " 'to',\n",
       " 'send',\n",
       " 'messages',\n",
       " 'to',\n",
       " 'each',\n",
       " 'other',\n",
       " '.',\n",
       " 'Next',\n",
       " ',',\n",
       " 'the',\n",
       " 'network',\n",
       " 'is',\n",
       " 'asked',\n",
       " 'to',\n",
       " 'solve',\n",
       " 'a',\n",
       " 'problem',\n",
       " ',',\n",
       " 'which',\n",
       " 'it',\n",
       " 'attempts',\n",
       " 'to',\n",
       " 'do',\n",
       " 'over',\n",
       " 'and',\n",
       " 'over',\n",
       " ',',\n",
       " 'each',\n",
       " 'time',\n",
       " 'strengthening',\n",
       " 'the',\n",
       " 'connections',\n",
       " 'that',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'success',\n",
       " 'and',\n",
       " 'diminishing',\n",
       " 'those',\n",
       " 'that',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'failure',\n",
       " '.',\n",
       " 'For',\n",
       " 'a',\n",
       " 'more',\n",
       " 'detailed',\n",
       " 'introduction',\n",
       " 'to',\n",
       " 'neural',\n",
       " 'networks',\n",
       " ',',\n",
       " 'Michael',\n",
       " 'Nielsen',\n",
       " '’',\n",
       " 's',\n",
       " 'Neural',\n",
       " 'Networks',\n",
       " 'and',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'place',\n",
       " 'to',\n",
       " 'start',\n",
       " '.',\n",
       " 'For',\n",
       " 'a',\n",
       " 'more',\n",
       " 'technical',\n",
       " 'overview',\n",
       " ',',\n",
       " 'try',\n",
       " 'Deep',\n",
       " 'Learning',\n",
       " 'by',\n",
       " 'Ian',\n",
       " 'Goodfellow',\n",
       " ',',\n",
       " 'Yoshua',\n",
       " 'Bengio',\n",
       " ',',\n",
       " 'and',\n",
       " 'Aaron',\n",
       " 'Courville',\n",
       " '.',\n",
       " 'This',\n",
       " 'Is',\n",
       " 'Cool',\n",
       " ',',\n",
       " 'Can',\n",
       " 'I',\n",
       " 'Repurpose',\n",
       " 'It',\n",
       " '?',\n",
       " 'Please',\n",
       " 'do',\n",
       " '!',\n",
       " 'We',\n",
       " '’',\n",
       " 've',\n",
       " 'open',\n",
       " 'sourced',\n",
       " 'it',\n",
       " 'on',\n",
       " 'GitHub',\n",
       " 'with',\n",
       " 'the',\n",
       " 'hope',\n",
       " 'that',\n",
       " 'it',\n",
       " 'can',\n",
       " 'make',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'a',\n",
       " 'little',\n",
       " 'more',\n",
       " 'accessible',\n",
       " 'and',\n",
       " 'easier',\n",
       " 'to',\n",
       " 'learn',\n",
       " '.',\n",
       " 'You',\n",
       " '’',\n",
       " 're',\n",
       " 'free',\n",
       " 'to',\n",
       " 'use',\n",
       " 'it',\n",
       " 'in',\n",
       " 'any',\n",
       " 'way',\n",
       " 'that',\n",
       " 'follows',\n",
       " 'our',\n",
       " 'Apache',\n",
       " 'License',\n",
       " '.',\n",
       " 'And',\n",
       " 'if',\n",
       " 'you',\n",
       " 'have',\n",
       " 'any',\n",
       " 'suggestions',\n",
       " 'for',\n",
       " 'additions',\n",
       " 'or',\n",
       " 'changes',\n",
       " ',',\n",
       " 'please',\n",
       " 'let',\n",
       " 'us',\n",
       " 'know',\n",
       " '.',\n",
       " 'We',\n",
       " '’',\n",
       " 've',\n",
       " 'also',\n",
       " 'provided',\n",
       " 'some',\n",
       " 'controls',\n",
       " 'below',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'you',\n",
       " 'tailor',\n",
       " 'the',\n",
       " 'playground',\n",
       " 'to',\n",
       " 'a',\n",
       " 'specific',\n",
       " 'topic',\n",
       " 'or',\n",
       " 'lesson',\n",
       " '.',\n",
       " 'Just',\n",
       " 'choose',\n",
       " 'which',\n",
       " 'features',\n",
       " 'you',\n",
       " '’',\n",
       " 'd',\n",
       " 'like',\n",
       " 'to',\n",
       " 'be',\n",
       " 'visible',\n",
       " 'below',\n",
       " 'then',\n",
       " 'save',\n",
       " 'this',\n",
       " 'link',\n",
       " ',',\n",
       " 'or',\n",
       " 'refresh',\n",
       " 'the',\n",
       " 'page',\n",
       " '.',\n",
       " 'What',\n",
       " 'Do',\n",
       " 'All',\n",
       " 'the',\n",
       " 'Colors',\n",
       " 'Mean',\n",
       " '?',\n",
       " 'Orange',\n",
       " 'and',\n",
       " 'blue',\n",
       " 'are',\n",
       " 'used',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'visualization',\n",
       " 'in',\n",
       " 'slightly',\n",
       " 'different',\n",
       " 'ways',\n",
       " ',',\n",
       " 'but',\n",
       " 'in',\n",
       " 'general',\n",
       " 'orange',\n",
       " 'shows',\n",
       " 'negative',\n",
       " 'values',\n",
       " 'while',\n",
       " 'blue',\n",
       " 'shows',\n",
       " 'positive',\n",
       " 'values',\n",
       " '.',\n",
       " 'The',\n",
       " 'data',\n",
       " 'points',\n",
       " '(',\n",
       " 'represented',\n",
       " 'by',\n",
       " 'small',\n",
       " 'circles',\n",
       " ')',\n",
       " 'are',\n",
       " 'initially',\n",
       " 'colored',\n",
       " 'orange',\n",
       " 'or',\n",
       " 'blue',\n",
       " ',',\n",
       " 'which',\n",
       " 'correspond',\n",
       " 'to',\n",
       " 'positive',\n",
       " 'one',\n",
       " 'and',\n",
       " 'negative',\n",
       " 'one',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'hidden',\n",
       " 'layers',\n",
       " ',',\n",
       " 'the',\n",
       " 'lines',\n",
       " 'are',\n",
       " 'colored',\n",
       " 'by',\n",
       " 'the',\n",
       " 'weights',\n",
       " 'of',\n",
       " 'the',\n",
       " 'connections',\n",
       " 'between',\n",
       " 'neurons',\n",
       " '.',\n",
       " 'Blue',\n",
       " 'shows',\n",
       " 'a',\n",
       " 'positive',\n",
       " 'weight',\n",
       " ',',\n",
       " 'which',\n",
       " 'means',\n",
       " 'the',\n",
       " 'network',\n",
       " 'is',\n",
       " 'using',\n",
       " 'that',\n",
       " 'output',\n",
       " 'of',\n",
       " 'the',\n",
       " 'neuron',\n",
       " 'as',\n",
       " 'given',\n",
       " '.',\n",
       " 'An',\n",
       " 'orange',\n",
       " 'line',\n",
       " 'shows',\n",
       " 'that',\n",
       " 'the',\n",
       " 'network',\n",
       " 'is',\n",
       " 'assiging',\n",
       " 'a',\n",
       " 'negative',\n",
       " 'weight',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'output',\n",
       " 'layer',\n",
       " ',',\n",
       " 'the',\n",
       " 'dots',\n",
       " 'are',\n",
       " 'colored',\n",
       " 'orange',\n",
       " 'or',\n",
       " 'blue',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'their',\n",
       " 'original',\n",
       " 'values',\n",
       " '.',\n",
       " 'The',\n",
       " 'background',\n",
       " 'color',\n",
       " 'shows',\n",
       " 'what',\n",
       " 'the',\n",
       " 'network',\n",
       " 'is',\n",
       " 'predicting',\n",
       " 'for',\n",
       " 'a',\n",
       " 'particular',\n",
       " 'area',\n",
       " '.',\n",
       " 'The',\n",
       " 'intensity',\n",
       " 'of',\n",
       " 'the',\n",
       " 'color',\n",
       " 'shows',\n",
       " 'how',\n",
       " 'confident',\n",
       " 'that',\n",
       " 'prediction',\n",
       " 'is',\n",
       " '.',\n",
       " 'What',\n",
       " 'Library',\n",
       " 'Are',\n",
       " 'You',\n",
       " 'Using',\n",
       " '?',\n",
       " 'We',\n",
       " 'wrote',\n",
       " 'a',\n",
       " 'tiny',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'library',\n",
       " 'that',\n",
       " 'meets',\n",
       " 'the',\n",
       " 'demands',\n",
       " 'of',\n",
       " 'this',\n",
       " 'educational',\n",
       " 'visualization',\n",
       " '.',\n",
       " 'For',\n",
       " 'real-world',\n",
       " 'applications',\n",
       " ',',\n",
       " 'consider',\n",
       " 'the',\n",
       " 'TensorFlow',\n",
       " 'library',\n",
       " '.',\n",
       " 'Credits',\n",
       " 'This',\n",
       " 'was',\n",
       " 'created',\n",
       " 'by',\n",
       " 'Daniel',\n",
       " 'Smilkov',\n",
       " 'and',\n",
       " 'Shan',\n",
       " 'Carter',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'continuation',\n",
       " 'of',\n",
       " 'many',\n",
       " 'people',\n",
       " '’',\n",
       " 's',\n",
       " 'previous',\n",
       " 'work',\n",
       " '—',\n",
       " 'most',\n",
       " 'notably',\n",
       " 'Andrej',\n",
       " 'Karpathy',\n",
       " '’',\n",
       " 's',\n",
       " 'convnet.js',\n",
       " 'demo',\n",
       " 'and',\n",
       " 'Chris',\n",
       " 'Olah',\n",
       " '’',\n",
       " 's',\n",
       " 'articles',\n",
       " 'about',\n",
       " 'neural',\n",
       " 'networks',\n",
       " '.',\n",
       " 'Many',\n",
       " 'thanks',\n",
       " 'also',\n",
       " 'to',\n",
       " 'D.',\n",
       " 'Sculley',\n",
       " 'for',\n",
       " 'help',\n",
       " 'with',\n",
       " 'the',\n",
       " 'original',\n",
       " 'idea',\n",
       " 'and',\n",
       " 'to',\n",
       " 'Fernanda',\n",
       " 'Viégas',\n",
       " 'and',\n",
       " 'Martin',\n",
       " 'Wattenberg',\n",
       " 'and',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Big',\n",
       " 'Picture',\n",
       " 'and',\n",
       " 'Google',\n",
       " 'Brain',\n",
       " 'teams',\n",
       " 'for',\n",
       " 'feedback',\n",
       " 'and',\n",
       " 'guidance',\n",
       " '.',\n",
       " 'Source',\n",
       " 'on',\n",
       " 'GitHub']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we remove punctuations, change the words into lowercase, remove stopwords and remove numbers from the list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_web = [''.join(char for char in strings if char not in string.punctuation) for strings in tokens_web]\n",
    "\n",
    "punc_web = [word for word in punc_web if word]\n",
    "\n",
    "lower_web = [word.lower() for word in punc_web]\n",
    "\n",
    "filtered_web = [word for word in lower_web if word not in stopwords.words('english')]\n",
    "\n",
    "no_digit_web = [x for x in filtered_web if not (x.isdigit() \n",
    "                                         or x[0] == '-' and x[1:].isdigit())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer() \n",
    "final_web = [ps.stem(word) for word in no_digit_web ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neural',\n",
       " 'network',\n",
       " 'playground',\n",
       " 'tinker',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'right',\n",
       " 'browserdon',\n",
       " '’',\n",
       " 'worri',\n",
       " '’',\n",
       " 'break',\n",
       " 'promis',\n",
       " 'replay',\n",
       " 'playarrow',\n",
       " 'paus',\n",
       " 'skipnext',\n",
       " 'epoch',\n",
       " 'learn',\n",
       " 'rate',\n",
       " 'activ',\n",
       " 'relu',\n",
       " 'tanh',\n",
       " 'sigmoid',\n",
       " 'linear',\n",
       " 'regular',\n",
       " 'none',\n",
       " 'l1',\n",
       " 'l2',\n",
       " 'regular',\n",
       " 'rate',\n",
       " 'problem',\n",
       " 'type',\n",
       " 'classif',\n",
       " 'regress',\n",
       " 'data',\n",
       " 'dataset',\n",
       " 'want',\n",
       " 'use',\n",
       " 'ratio',\n",
       " 'train',\n",
       " 'test',\n",
       " 'data',\n",
       " 'xx',\n",
       " 'nois',\n",
       " 'xx',\n",
       " 'batch',\n",
       " 'size',\n",
       " 'xx',\n",
       " 'regener',\n",
       " 'featur',\n",
       " 'properti',\n",
       " 'want',\n",
       " 'feed',\n",
       " 'click',\n",
       " 'anywher',\n",
       " 'edit',\n",
       " 'weightbia',\n",
       " 'output',\n",
       " 'one',\n",
       " 'neuron',\n",
       " 'hover',\n",
       " 'see',\n",
       " 'larger',\n",
       " 'output',\n",
       " 'mix',\n",
       " 'vari',\n",
       " 'weight',\n",
       " 'shown',\n",
       " 'thick',\n",
       " 'line',\n",
       " 'add',\n",
       " 'remov',\n",
       " 'output',\n",
       " 'test',\n",
       " 'loss',\n",
       " 'train',\n",
       " 'loss',\n",
       " 'color',\n",
       " 'show',\n",
       " 'data',\n",
       " 'neuron',\n",
       " 'weight',\n",
       " 'valu',\n",
       " 'show',\n",
       " 'test',\n",
       " 'data',\n",
       " 'discret',\n",
       " 'output',\n",
       " 'keyboardarrowdown',\n",
       " 'um',\n",
       " 'neural',\n",
       " 'network',\n",
       " '’',\n",
       " 'techniqu',\n",
       " 'build',\n",
       " 'comput',\n",
       " 'program',\n",
       " 'learn',\n",
       " 'data',\n",
       " 'base',\n",
       " 'loos',\n",
       " 'think',\n",
       " 'human',\n",
       " 'brain',\n",
       " 'work',\n",
       " 'first',\n",
       " 'collect',\n",
       " 'softwar',\n",
       " '“',\n",
       " 'neuron',\n",
       " '”',\n",
       " 'creat',\n",
       " 'connect',\n",
       " 'togeth',\n",
       " 'allow',\n",
       " 'send',\n",
       " 'messag',\n",
       " 'next',\n",
       " 'network',\n",
       " 'ask',\n",
       " 'solv',\n",
       " 'problem',\n",
       " 'attempt',\n",
       " 'time',\n",
       " 'strengthen',\n",
       " 'connect',\n",
       " 'lead',\n",
       " 'success',\n",
       " 'diminish',\n",
       " 'lead',\n",
       " 'failur',\n",
       " 'detail',\n",
       " 'introduct',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'michael',\n",
       " 'nielsen',\n",
       " '’',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'deep',\n",
       " 'learn',\n",
       " 'good',\n",
       " 'place',\n",
       " 'start',\n",
       " 'technic',\n",
       " 'overview',\n",
       " 'tri',\n",
       " 'deep',\n",
       " 'learn',\n",
       " 'ian',\n",
       " 'goodfellow',\n",
       " 'yoshua',\n",
       " 'bengio',\n",
       " 'aaron',\n",
       " 'courvil',\n",
       " 'cool',\n",
       " 'repurpos',\n",
       " 'pleas',\n",
       " '’',\n",
       " 'open',\n",
       " 'sourc',\n",
       " 'github',\n",
       " 'hope',\n",
       " 'make',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'littl',\n",
       " 'access',\n",
       " 'easier',\n",
       " 'learn',\n",
       " '’',\n",
       " 'free',\n",
       " 'use',\n",
       " 'way',\n",
       " 'follow',\n",
       " 'apach',\n",
       " 'licens',\n",
       " 'suggest',\n",
       " 'addit',\n",
       " 'chang',\n",
       " 'pleas',\n",
       " 'let',\n",
       " 'us',\n",
       " 'know',\n",
       " '’',\n",
       " 'also',\n",
       " 'provid',\n",
       " 'control',\n",
       " 'enabl',\n",
       " 'tailor',\n",
       " 'playground',\n",
       " 'specif',\n",
       " 'topic',\n",
       " 'lesson',\n",
       " 'choos',\n",
       " 'featur',\n",
       " '’',\n",
       " 'like',\n",
       " 'visibl',\n",
       " 'save',\n",
       " 'link',\n",
       " 'refresh',\n",
       " 'page',\n",
       " 'color',\n",
       " 'mean',\n",
       " 'orang',\n",
       " 'blue',\n",
       " 'use',\n",
       " 'throughout',\n",
       " 'visual',\n",
       " 'slightli',\n",
       " 'differ',\n",
       " 'way',\n",
       " 'gener',\n",
       " 'orang',\n",
       " 'show',\n",
       " 'neg',\n",
       " 'valu',\n",
       " 'blue',\n",
       " 'show',\n",
       " 'posit',\n",
       " 'valu',\n",
       " 'data',\n",
       " 'point',\n",
       " 'repres',\n",
       " 'small',\n",
       " 'circl',\n",
       " 'initi',\n",
       " 'color',\n",
       " 'orang',\n",
       " 'blue',\n",
       " 'correspond',\n",
       " 'posit',\n",
       " 'one',\n",
       " 'neg',\n",
       " 'one',\n",
       " 'hidden',\n",
       " 'layer',\n",
       " 'line',\n",
       " 'color',\n",
       " 'weight',\n",
       " 'connect',\n",
       " 'neuron',\n",
       " 'blue',\n",
       " 'show',\n",
       " 'posit',\n",
       " 'weight',\n",
       " 'mean',\n",
       " 'network',\n",
       " 'use',\n",
       " 'output',\n",
       " 'neuron',\n",
       " 'given',\n",
       " 'orang',\n",
       " 'line',\n",
       " 'show',\n",
       " 'network',\n",
       " 'assig',\n",
       " 'neg',\n",
       " 'weight',\n",
       " 'output',\n",
       " 'layer',\n",
       " 'dot',\n",
       " 'color',\n",
       " 'orang',\n",
       " 'blue',\n",
       " 'depend',\n",
       " 'origin',\n",
       " 'valu',\n",
       " 'background',\n",
       " 'color',\n",
       " 'show',\n",
       " 'network',\n",
       " 'predict',\n",
       " 'particular',\n",
       " 'area',\n",
       " 'intens',\n",
       " 'color',\n",
       " 'show',\n",
       " 'confid',\n",
       " 'predict',\n",
       " 'librari',\n",
       " 'use',\n",
       " 'wrote',\n",
       " 'tini',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'librari',\n",
       " 'meet',\n",
       " 'demand',\n",
       " 'educ',\n",
       " 'visual',\n",
       " 'realworld',\n",
       " 'applic',\n",
       " 'consid',\n",
       " 'tensorflow',\n",
       " 'librari',\n",
       " 'credit',\n",
       " 'creat',\n",
       " 'daniel',\n",
       " 'smilkov',\n",
       " 'carter',\n",
       " 'continu',\n",
       " 'mani',\n",
       " 'peopl',\n",
       " '’',\n",
       " 'previou',\n",
       " 'work',\n",
       " '—',\n",
       " 'notabl',\n",
       " 'andrej',\n",
       " 'karpathi',\n",
       " '’',\n",
       " 'convnetj',\n",
       " 'demo',\n",
       " 'chri',\n",
       " 'olah',\n",
       " '’',\n",
       " 'articl',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'mani',\n",
       " 'thank',\n",
       " 'also',\n",
       " 'sculley',\n",
       " 'help',\n",
       " 'origin',\n",
       " 'idea',\n",
       " 'fernanda',\n",
       " 'viéga',\n",
       " 'martin',\n",
       " 'wattenberg',\n",
       " 'rest',\n",
       " 'big',\n",
       " 'pictur',\n",
       " 'googl',\n",
       " 'brain',\n",
       " 'team',\n",
       " 'feedback',\n",
       " 'guidanc',\n",
       " 'sourc',\n",
       " 'github']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean_web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ss2.txt')\n",
    "text_file = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_text = word_tokenize(text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Predict',\n",
       " 'Shakespeare',\n",
       " 'with',\n",
       " 'Cloud',\n",
       " 'TPUs',\n",
       " 'and',\n",
       " 'Keras',\n",
       " 'Overview',\n",
       " 'This',\n",
       " 'example',\n",
       " 'uses',\n",
       " 'tf.keras',\n",
       " 'to',\n",
       " 'build',\n",
       " 'a',\n",
       " 'language',\n",
       " 'model',\n",
       " 'and',\n",
       " 'train',\n",
       " 'it',\n",
       " 'on',\n",
       " 'a',\n",
       " 'Cloud',\n",
       " 'TPU',\n",
       " '.',\n",
       " 'This',\n",
       " 'language',\n",
       " 'model',\n",
       " 'predicts',\n",
       " 'the',\n",
       " 'next',\n",
       " 'character',\n",
       " 'of',\n",
       " 'text',\n",
       " 'given',\n",
       " 'the',\n",
       " 'text',\n",
       " 'so',\n",
       " 'far',\n",
       " '.',\n",
       " 'The',\n",
       " 'trained',\n",
       " 'model',\n",
       " 'can',\n",
       " 'generate',\n",
       " 'new',\n",
       " 'snippets',\n",
       " 'of',\n",
       " 'text',\n",
       " 'that',\n",
       " 'read',\n",
       " 'in',\n",
       " 'a',\n",
       " 'similar',\n",
       " 'style',\n",
       " 'to',\n",
       " 'the',\n",
       " 'text',\n",
       " 'training',\n",
       " 'data',\n",
       " '.',\n",
       " 'The',\n",
       " 'model',\n",
       " 'trains',\n",
       " 'for',\n",
       " '10',\n",
       " 'epochs',\n",
       " 'and',\n",
       " 'completes',\n",
       " 'in',\n",
       " 'approximately',\n",
       " '5',\n",
       " 'minutes',\n",
       " '.',\n",
       " 'This',\n",
       " 'notebook',\n",
       " 'is',\n",
       " 'hosted',\n",
       " 'on',\n",
       " 'GitHub',\n",
       " '.',\n",
       " 'To',\n",
       " 'view',\n",
       " 'it',\n",
       " 'in',\n",
       " 'its',\n",
       " 'original',\n",
       " 'repository',\n",
       " ',',\n",
       " 'after',\n",
       " 'opening',\n",
       " 'the',\n",
       " 'notebook',\n",
       " ',',\n",
       " 'select',\n",
       " 'File',\n",
       " '>',\n",
       " 'View',\n",
       " 'on',\n",
       " 'GitHub',\n",
       " '.',\n",
       " 'Learning',\n",
       " 'objectives',\n",
       " 'In',\n",
       " 'this',\n",
       " 'Colab',\n",
       " ',',\n",
       " 'you',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'how',\n",
       " 'to',\n",
       " ':',\n",
       " 'Build',\n",
       " 'a',\n",
       " 'two-layer',\n",
       " ',',\n",
       " 'forward-LSTM',\n",
       " 'model',\n",
       " '.',\n",
       " 'Convert',\n",
       " 'a',\n",
       " 'tf.keras',\n",
       " 'model',\n",
       " 'to',\n",
       " 'an',\n",
       " 'equivalent',\n",
       " 'TPU',\n",
       " 'version',\n",
       " 'and',\n",
       " 'then',\n",
       " 'use',\n",
       " 'the',\n",
       " 'standard',\n",
       " 'Keras',\n",
       " 'methods',\n",
       " 'to',\n",
       " 'train',\n",
       " ':',\n",
       " 'fit',\n",
       " ',',\n",
       " 'predict',\n",
       " ',',\n",
       " 'and',\n",
       " 'evaluate',\n",
       " '.',\n",
       " 'Use',\n",
       " 'the',\n",
       " 'trained',\n",
       " 'model',\n",
       " 'to',\n",
       " 'make',\n",
       " 'predictions',\n",
       " 'and',\n",
       " 'generate',\n",
       " 'your',\n",
       " 'own',\n",
       " 'Shakespeare-esque',\n",
       " 'play',\n",
       " '.',\n",
       " 'Instructions',\n",
       " 'Train',\n",
       " 'on',\n",
       " 'TPU',\n",
       " 'On',\n",
       " 'the',\n",
       " 'main',\n",
       " 'menu',\n",
       " ',',\n",
       " 'click',\n",
       " 'Runtime',\n",
       " 'and',\n",
       " 'select',\n",
       " 'Change',\n",
       " 'runtime',\n",
       " 'type',\n",
       " '.',\n",
       " 'Set',\n",
       " '``',\n",
       " 'TPU',\n",
       " \"''\",\n",
       " 'as',\n",
       " 'the',\n",
       " 'hardware',\n",
       " 'accelerator',\n",
       " '.',\n",
       " 'Click',\n",
       " 'Runtime',\n",
       " 'again',\n",
       " 'and',\n",
       " 'select',\n",
       " 'Runtime',\n",
       " '>',\n",
       " 'Run',\n",
       " 'All',\n",
       " '.',\n",
       " 'You',\n",
       " 'can',\n",
       " 'also',\n",
       " 'run',\n",
       " 'the',\n",
       " 'cells',\n",
       " 'manually',\n",
       " 'with',\n",
       " 'Shift-ENTER',\n",
       " '.',\n",
       " 'TPUs',\n",
       " 'are',\n",
       " 'located',\n",
       " 'in',\n",
       " 'Google',\n",
       " 'Cloud',\n",
       " ',',\n",
       " 'for',\n",
       " 'optimal',\n",
       " 'performance',\n",
       " ',',\n",
       " 'they',\n",
       " 'read',\n",
       " 'data',\n",
       " 'directly',\n",
       " 'from',\n",
       " 'Google',\n",
       " 'Cloud',\n",
       " 'Storage',\n",
       " '(',\n",
       " 'GCS',\n",
       " ')',\n",
       " 'Data',\n",
       " ',',\n",
       " 'model',\n",
       " ',',\n",
       " 'and',\n",
       " 'training',\n",
       " 'In',\n",
       " 'this',\n",
       " 'example',\n",
       " ',',\n",
       " 'you',\n",
       " 'train',\n",
       " 'the',\n",
       " 'model',\n",
       " 'on',\n",
       " 'the',\n",
       " 'combined',\n",
       " 'works',\n",
       " 'of',\n",
       " 'William',\n",
       " 'Shakespeare',\n",
       " ',',\n",
       " 'then',\n",
       " 'use',\n",
       " 'the',\n",
       " 'model',\n",
       " 'to',\n",
       " 'compose',\n",
       " 'a',\n",
       " 'play',\n",
       " 'in',\n",
       " 'the',\n",
       " 'style',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Great',\n",
       " 'Bard',\n",
       " ':',\n",
       " 'Loves',\n",
       " 'that',\n",
       " 'led',\n",
       " 'me',\n",
       " 'no',\n",
       " 'dumbs',\n",
       " 'lack',\n",
       " 'her',\n",
       " 'Berjoy',\n",
       " \"'s\",\n",
       " 'face',\n",
       " 'with',\n",
       " 'her',\n",
       " 'to-day',\n",
       " '.',\n",
       " 'The',\n",
       " 'spirits',\n",
       " 'roar',\n",
       " \"'d\",\n",
       " ';',\n",
       " 'which',\n",
       " 'shames',\n",
       " 'which',\n",
       " 'within',\n",
       " 'his',\n",
       " 'powers',\n",
       " 'Which',\n",
       " 'tied',\n",
       " 'up',\n",
       " 'remedies',\n",
       " 'lending',\n",
       " 'with',\n",
       " 'occasion',\n",
       " ',',\n",
       " 'A',\n",
       " 'loud',\n",
       " 'and',\n",
       " 'Lancaster',\n",
       " ',',\n",
       " 'stabb',\n",
       " \"'d\",\n",
       " 'in',\n",
       " 'me',\n",
       " 'Upon',\n",
       " 'my',\n",
       " 'sword',\n",
       " 'for',\n",
       " 'ever',\n",
       " ':',\n",
       " \"'Agripo'er\",\n",
       " ',',\n",
       " 'his',\n",
       " 'days',\n",
       " 'let',\n",
       " 'me',\n",
       " 'free',\n",
       " '.',\n",
       " 'Stop',\n",
       " 'it',\n",
       " 'of',\n",
       " 'that',\n",
       " 'word',\n",
       " ',',\n",
       " 'be',\n",
       " 'so',\n",
       " ':',\n",
       " 'at',\n",
       " 'Lear',\n",
       " ',',\n",
       " 'When',\n",
       " 'I',\n",
       " 'did',\n",
       " 'profess',\n",
       " 'the',\n",
       " 'hour-stranger',\n",
       " 'for',\n",
       " 'my',\n",
       " 'life',\n",
       " ',',\n",
       " 'When',\n",
       " 'I',\n",
       " 'did',\n",
       " 'sink',\n",
       " 'to',\n",
       " 'be',\n",
       " 'cried',\n",
       " 'how',\n",
       " 'for',\n",
       " 'aught',\n",
       " ';',\n",
       " 'Some',\n",
       " 'beds',\n",
       " 'which',\n",
       " 'seeks',\n",
       " 'chaste',\n",
       " 'senses',\n",
       " 'prove',\n",
       " 'burning',\n",
       " ';',\n",
       " 'But',\n",
       " 'he',\n",
       " 'perforces',\n",
       " 'seen',\n",
       " 'in',\n",
       " 'her',\n",
       " 'eyes',\n",
       " 'so',\n",
       " 'fast',\n",
       " ';',\n",
       " 'And',\n",
       " '_',\n",
       " 'Download',\n",
       " 'data',\n",
       " 'Download',\n",
       " 'The',\n",
       " 'Complete',\n",
       " 'Works',\n",
       " 'of',\n",
       " 'William',\n",
       " 'Shakespeare',\n",
       " 'as',\n",
       " 'a',\n",
       " 'single',\n",
       " 'text',\n",
       " 'file',\n",
       " 'from',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " '.',\n",
       " 'You',\n",
       " 'use',\n",
       " 'snippets',\n",
       " 'from',\n",
       " 'this',\n",
       " 'file',\n",
       " 'as',\n",
       " 'the',\n",
       " 'training',\n",
       " 'data',\n",
       " 'for',\n",
       " 'the',\n",
       " 'model',\n",
       " '.',\n",
       " 'The',\n",
       " 'target',\n",
       " 'snippet',\n",
       " 'is',\n",
       " 'offset',\n",
       " 'by',\n",
       " 'one',\n",
       " 'character',\n",
       " '.',\n",
       " '[',\n",
       " ']',\n",
       " '!',\n",
       " 'wget',\n",
       " '--',\n",
       " 'show-progress',\n",
       " '--',\n",
       " 'continue',\n",
       " '-O',\n",
       " '/content/shakespeare.txt',\n",
       " 'http',\n",
       " ':',\n",
       " '//www.gutenberg.org/files/100/100-0.txt',\n",
       " 'Build',\n",
       " 'the',\n",
       " 'data',\n",
       " 'generator',\n",
       " '[',\n",
       " ']',\n",
       " 'import',\n",
       " 'numpy',\n",
       " 'as',\n",
       " 'np',\n",
       " 'import',\n",
       " 'six',\n",
       " 'import',\n",
       " 'tensorflow',\n",
       " 'as',\n",
       " 'tf',\n",
       " 'import',\n",
       " 'time',\n",
       " 'import',\n",
       " 'os',\n",
       " '#',\n",
       " 'This',\n",
       " 'address',\n",
       " 'identifies',\n",
       " 'the',\n",
       " 'TPU',\n",
       " 'we',\n",
       " \"'ll\",\n",
       " 'use',\n",
       " 'when',\n",
       " 'configuring',\n",
       " 'TensorFlow',\n",
       " '.',\n",
       " 'TPU_WORKER',\n",
       " '=',\n",
       " \"'grpc\",\n",
       " ':',\n",
       " '//',\n",
       " \"'\",\n",
       " '+',\n",
       " 'os.environ',\n",
       " '[',\n",
       " \"'COLAB_TPU_ADDR\",\n",
       " \"'\",\n",
       " ']',\n",
       " 'SHAKESPEARE_TXT',\n",
       " '=',\n",
       " \"'/content/shakespeare.txt'\",\n",
       " 'tf.logging.set_verbosity',\n",
       " '(',\n",
       " 'tf.logging.INFO',\n",
       " ')',\n",
       " 'def',\n",
       " 'transform',\n",
       " '(',\n",
       " 'txt',\n",
       " ',',\n",
       " 'pad_to=None',\n",
       " ')',\n",
       " ':',\n",
       " '#',\n",
       " 'drop',\n",
       " 'any',\n",
       " 'non-ascii',\n",
       " 'characters',\n",
       " 'output',\n",
       " '=',\n",
       " 'np.asarray',\n",
       " '(',\n",
       " '[',\n",
       " 'ord',\n",
       " '(',\n",
       " 'c',\n",
       " ')',\n",
       " 'for',\n",
       " 'c',\n",
       " 'in',\n",
       " 'txt',\n",
       " 'if',\n",
       " 'ord',\n",
       " '(',\n",
       " 'c',\n",
       " ')',\n",
       " '<',\n",
       " '255',\n",
       " ']',\n",
       " ',',\n",
       " 'dtype=np.int32',\n",
       " ')',\n",
       " 'if',\n",
       " 'pad_to',\n",
       " 'is',\n",
       " 'not',\n",
       " 'None',\n",
       " ':',\n",
       " 'output',\n",
       " '=',\n",
       " 'output',\n",
       " '[',\n",
       " ':',\n",
       " 'pad_to',\n",
       " ']',\n",
       " 'output',\n",
       " '=',\n",
       " 'np.concatenate',\n",
       " '(',\n",
       " '[',\n",
       " 'np.zeros',\n",
       " '(',\n",
       " '[',\n",
       " 'pad_to',\n",
       " '-',\n",
       " 'len',\n",
       " '(',\n",
       " 'txt',\n",
       " ')',\n",
       " ']',\n",
       " ',',\n",
       " 'dtype=np.int32',\n",
       " ')',\n",
       " ',',\n",
       " 'output',\n",
       " ',',\n",
       " ']',\n",
       " ')',\n",
       " 'return',\n",
       " 'output',\n",
       " 'def',\n",
       " 'training_generator',\n",
       " '(',\n",
       " 'seq_len=100',\n",
       " ',',\n",
       " 'batch_size=1024',\n",
       " ')',\n",
       " ':',\n",
       " '``',\n",
       " \"''\",\n",
       " \"''\",\n",
       " 'A',\n",
       " 'generator',\n",
       " 'yields',\n",
       " '(',\n",
       " 'source',\n",
       " ',',\n",
       " 'target',\n",
       " ')',\n",
       " 'arrays',\n",
       " 'for',\n",
       " 'training',\n",
       " '.',\n",
       " \"''\",\n",
       " \"''\",\n",
       " \"''\",\n",
       " 'with',\n",
       " 'tf.gfile.GFile',\n",
       " '(',\n",
       " 'SHAKESPEARE_TXT',\n",
       " ',',\n",
       " \"'\",\n",
       " 'r',\n",
       " \"'\",\n",
       " ')',\n",
       " 'as',\n",
       " 'f',\n",
       " ':',\n",
       " 'txt',\n",
       " '=',\n",
       " 'f.read',\n",
       " '(',\n",
       " ')',\n",
       " 'tf.logging.info',\n",
       " '(',\n",
       " \"'Input\",\n",
       " 'text',\n",
       " '[',\n",
       " '%',\n",
       " 'd',\n",
       " ']',\n",
       " '%',\n",
       " 's',\n",
       " \"'\",\n",
       " ',',\n",
       " 'len',\n",
       " '(',\n",
       " 'txt',\n",
       " ')',\n",
       " ',',\n",
       " 'txt',\n",
       " '[',\n",
       " ':50',\n",
       " ']',\n",
       " ')',\n",
       " 'source',\n",
       " '=',\n",
       " 'transform',\n",
       " '(',\n",
       " 'txt',\n",
       " ')',\n",
       " 'while',\n",
       " 'True',\n",
       " ':',\n",
       " 'offsets',\n",
       " '=',\n",
       " 'np.random.randint',\n",
       " '(',\n",
       " '0',\n",
       " ',',\n",
       " 'len',\n",
       " '(',\n",
       " 'source',\n",
       " ')',\n",
       " '-',\n",
       " 'seq_len',\n",
       " ',',\n",
       " 'batch_size',\n",
       " ')',\n",
       " '#',\n",
       " 'Our',\n",
       " 'model',\n",
       " 'uses',\n",
       " 'sparse',\n",
       " 'crossentropy',\n",
       " 'loss',\n",
       " ',',\n",
       " 'but',\n",
       " 'Keras',\n",
       " 'requires',\n",
       " 'labels',\n",
       " '#',\n",
       " 'to',\n",
       " 'have',\n",
       " 'the',\n",
       " 'same',\n",
       " 'rank',\n",
       " 'as',\n",
       " 'the',\n",
       " 'input',\n",
       " 'logits',\n",
       " '.',\n",
       " 'We',\n",
       " 'add',\n",
       " 'an',\n",
       " 'empty',\n",
       " 'final',\n",
       " '#',\n",
       " 'dimension',\n",
       " 'to',\n",
       " 'account',\n",
       " 'for',\n",
       " 'this',\n",
       " '.',\n",
       " 'yield',\n",
       " '(',\n",
       " 'np.stack',\n",
       " '(',\n",
       " '[',\n",
       " 'source',\n",
       " '[',\n",
       " 'idx',\n",
       " ':',\n",
       " 'idx',\n",
       " '+',\n",
       " 'seq_len',\n",
       " ']',\n",
       " 'for',\n",
       " 'idx',\n",
       " 'in',\n",
       " 'offsets',\n",
       " ']',\n",
       " ')',\n",
       " ',',\n",
       " 'np.expand_dims',\n",
       " '(',\n",
       " 'np.stack',\n",
       " '(',\n",
       " '[',\n",
       " 'source',\n",
       " '[',\n",
       " 'idx',\n",
       " '+',\n",
       " '1',\n",
       " ':',\n",
       " 'idx',\n",
       " '+',\n",
       " 'seq_len',\n",
       " '+',\n",
       " '1',\n",
       " ']',\n",
       " 'for',\n",
       " 'idx',\n",
       " 'in',\n",
       " 'offsets',\n",
       " ']',\n",
       " ')',\n",
       " ',',\n",
       " '-1',\n",
       " ')',\n",
       " ',',\n",
       " ')',\n",
       " 'six.next',\n",
       " '(',\n",
       " 'training_generator',\n",
       " '(',\n",
       " 'seq_len=10',\n",
       " ',',\n",
       " 'batch_size=1',\n",
       " ')',\n",
       " ')',\n",
       " 'Build',\n",
       " 'the',\n",
       " 'model',\n",
       " 'The',\n",
       " 'model',\n",
       " 'is',\n",
       " 'defined',\n",
       " 'as',\n",
       " 'a',\n",
       " 'two-layer',\n",
       " ',',\n",
       " 'forward-LSTMwith',\n",
       " 'two',\n",
       " 'changes',\n",
       " 'from',\n",
       " 'the',\n",
       " 'tf.keras',\n",
       " 'standard',\n",
       " 'LSTM',\n",
       " 'definition',\n",
       " ':',\n",
       " 'Define',\n",
       " 'the',\n",
       " 'input',\n",
       " 'shape',\n",
       " 'of',\n",
       " 'the',\n",
       " 'model',\n",
       " 'to',\n",
       " 'comply',\n",
       " 'with',\n",
       " 'the',\n",
       " 'XLA',\n",
       " 'compiler',\n",
       " \"'s\",\n",
       " 'static',\n",
       " 'shape',\n",
       " 'requirement',\n",
       " '.',\n",
       " 'Use',\n",
       " 'tf.train.Optimizer',\n",
       " 'instead',\n",
       " 'of',\n",
       " 'a',\n",
       " 'standard',\n",
       " 'Keras',\n",
       " 'optimizer',\n",
       " '(',\n",
       " 'Keras',\n",
       " 'optimizer',\n",
       " 'support',\n",
       " 'is',\n",
       " 'still',\n",
       " 'experimental',\n",
       " ')',\n",
       " '.',\n",
       " '[',\n",
       " ']',\n",
       " 'EMBEDDING_DIM',\n",
       " '=',\n",
       " '512',\n",
       " 'def',\n",
       " 'lstm_model',\n",
       " '(',\n",
       " 'seq_len=100',\n",
       " ',',\n",
       " 'batch_size=None',\n",
       " ',',\n",
       " 'stateful=True',\n",
       " ')',\n",
       " ':',\n",
       " '``',\n",
       " \"''\",\n",
       " \"''\",\n",
       " 'Language',\n",
       " 'model',\n",
       " ':',\n",
       " 'predict',\n",
       " 'the',\n",
       " 'next',\n",
       " 'word',\n",
       " 'given',\n",
       " 'the',\n",
       " 'current',\n",
       " 'word',\n",
       " '.',\n",
       " \"''\",\n",
       " \"''\",\n",
       " \"''\",\n",
       " 'source',\n",
       " '=',\n",
       " 'tf.keras.Input',\n",
       " '(',\n",
       " \"name='seed\",\n",
       " \"'\",\n",
       " ',',\n",
       " 'shape=',\n",
       " '(',\n",
       " 'seq_len',\n",
       " ',',\n",
       " ')',\n",
       " ',',\n",
       " 'batch_size=batch_size',\n",
       " ',',\n",
       " 'dtype=tf.int32',\n",
       " ')',\n",
       " 'embedding',\n",
       " '=',\n",
       " 'tf.keras.layers.Embedding',\n",
       " '(',\n",
       " 'input_dim=256',\n",
       " ',',\n",
       " 'output_dim=EMBEDDING_DIM',\n",
       " ')',\n",
       " '(',\n",
       " 'source',\n",
       " ')',\n",
       " 'lstm_1',\n",
       " '=',\n",
       " 'tf.keras.layers.LSTM',\n",
       " '(',\n",
       " 'EMBEDDING_DIM',\n",
       " ',',\n",
       " 'stateful=stateful',\n",
       " ',',\n",
       " 'return_sequences=True',\n",
       " ')',\n",
       " '(',\n",
       " 'embedding',\n",
       " ')',\n",
       " 'lstm_2',\n",
       " '=',\n",
       " 'tf.keras.layers.LSTM',\n",
       " '(',\n",
       " 'EMBEDDING_DIM',\n",
       " ',',\n",
       " 'stateful=stateful',\n",
       " ',',\n",
       " 'return_sequences=True',\n",
       " ')',\n",
       " '(',\n",
       " 'lstm_1',\n",
       " ')',\n",
       " 'predicted_char',\n",
       " '=',\n",
       " 'tf.keras.layers.TimeDistributed',\n",
       " '(',\n",
       " 'tf.keras.layers.Dense',\n",
       " '(',\n",
       " '256',\n",
       " ',',\n",
       " \"activation='softmax\",\n",
       " \"'\",\n",
       " ')',\n",
       " ')',\n",
       " '(',\n",
       " 'lstm_2',\n",
       " ')',\n",
       " 'model',\n",
       " '=',\n",
       " 'tf.keras.Model',\n",
       " '(',\n",
       " 'inputs=',\n",
       " '[',\n",
       " 'source',\n",
       " ']',\n",
       " ',',\n",
       " 'outputs=',\n",
       " '[',\n",
       " 'predicted_char',\n",
       " ']',\n",
       " ')',\n",
       " 'model.compile',\n",
       " '(',\n",
       " 'optimizer=tf.train.RMSPropOptimizer',\n",
       " '(',\n",
       " 'learning_rate=0.01',\n",
       " ')',\n",
       " ',',\n",
       " \"loss='sparse_categorical_crossentropy\",\n",
       " \"'\",\n",
       " ',',\n",
       " 'metrics=',\n",
       " '[',\n",
       " \"'sparse_categorical_accuracy\",\n",
       " \"'\",\n",
       " ']',\n",
       " ')',\n",
       " 'return',\n",
       " 'model',\n",
       " 'Train',\n",
       " 'the',\n",
       " 'model',\n",
       " 'The',\n",
       " 'tf.contrib.tpu.keras_to_tpu_model',\n",
       " 'function',\n",
       " 'converts',\n",
       " 'a',\n",
       " 'tf.keras',\n",
       " 'model',\n",
       " 'to',\n",
       " 'an',\n",
       " 'equivalent',\n",
       " 'TPU',\n",
       " 'version',\n",
       " '.',\n",
       " 'You',\n",
       " 'then',\n",
       " 'use',\n",
       " 'the',\n",
       " 'standard',\n",
       " 'Keras',\n",
       " 'methods',\n",
       " 'to',\n",
       " 'train',\n",
       " ':',\n",
       " 'fit',\n",
       " ',',\n",
       " 'predict',\n",
       " ',',\n",
       " 'and',\n",
       " 'evaluate',\n",
       " '.',\n",
       " '[',\n",
       " ']',\n",
       " 'tf.keras.backend.clear_session',\n",
       " '(',\n",
       " ')',\n",
       " 'training_model',\n",
       " '=',\n",
       " 'lstm_model',\n",
       " '(',\n",
       " 'seq_len=100',\n",
       " ',',\n",
       " 'batch_size=128',\n",
       " ',',\n",
       " 'stateful=False',\n",
       " ')',\n",
       " 'tpu_model',\n",
       " '=',\n",
       " 'tf.contrib.tpu.keras_to_tpu_model',\n",
       " '(',\n",
       " 'training_model',\n",
       " ',',\n",
       " 'strategy=tf.contrib.tpu.TPUDistributionStrategy',\n",
       " '(',\n",
       " 'tf.contrib.cluster_resolver.TPUClusterResolver',\n",
       " '(',\n",
       " 'TPU_WORKER',\n",
       " ')',\n",
       " ')',\n",
       " ')',\n",
       " 'tpu_model.fit_generator',\n",
       " '(',\n",
       " 'training_generator',\n",
       " '(',\n",
       " 'seq_len=100',\n",
       " ',',\n",
       " 'batch_size=1024',\n",
       " ')',\n",
       " ',',\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the same steps that we performed earlier. Remove punctuations, change the words into lowercase, remove stopwords and remove numbers from the list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_text = [''.join(char for char in strings if char not in string.punctuation) \n",
    "                   for strings in tokens_text]\n",
    "punc_text = [string for string in punc_text if string]\n",
    "lower_text = [x.lower() for x in punc_text]\n",
    "filtered_text = [word for word in lower_text if word not in stopwords.words('english')]\n",
    "no_digit_text = [x for x in filtered_text if not (x.isdigit() \n",
    "                                         or x[0] == '-' and x[1:].isdigit())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = [ps.stem(word) for word in no_digit_text ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predict',\n",
       " 'shakespear',\n",
       " 'cloud',\n",
       " 'tpu',\n",
       " 'kera',\n",
       " 'overview',\n",
       " 'exampl',\n",
       " 'use',\n",
       " 'tfkera',\n",
       " 'build',\n",
       " 'languag',\n",
       " 'model',\n",
       " 'train',\n",
       " 'cloud',\n",
       " 'tpu',\n",
       " 'languag',\n",
       " 'model',\n",
       " 'predict',\n",
       " 'next',\n",
       " 'charact',\n",
       " 'text',\n",
       " 'given',\n",
       " 'text',\n",
       " 'far',\n",
       " 'train',\n",
       " 'model',\n",
       " 'gener',\n",
       " 'new',\n",
       " 'snippet',\n",
       " 'text',\n",
       " 'read',\n",
       " 'similar',\n",
       " 'style',\n",
       " 'text',\n",
       " 'train',\n",
       " 'data',\n",
       " 'model',\n",
       " 'train',\n",
       " 'epoch',\n",
       " 'complet',\n",
       " 'approxim',\n",
       " 'minut',\n",
       " 'notebook',\n",
       " 'host',\n",
       " 'github',\n",
       " 'view',\n",
       " 'origin',\n",
       " 'repositori',\n",
       " 'open',\n",
       " 'notebook',\n",
       " 'select',\n",
       " 'file',\n",
       " 'view',\n",
       " 'github',\n",
       " 'learn',\n",
       " 'object',\n",
       " 'colab',\n",
       " 'learn',\n",
       " 'build',\n",
       " 'twolay',\n",
       " 'forwardlstm',\n",
       " 'model',\n",
       " 'convert',\n",
       " 'tfkera',\n",
       " 'model',\n",
       " 'equival',\n",
       " 'tpu',\n",
       " 'version',\n",
       " 'use',\n",
       " 'standard',\n",
       " 'kera',\n",
       " 'method',\n",
       " 'train',\n",
       " 'fit',\n",
       " 'predict',\n",
       " 'evalu',\n",
       " 'use',\n",
       " 'train',\n",
       " 'model',\n",
       " 'make',\n",
       " 'predict',\n",
       " 'gener',\n",
       " 'shakespeareesqu',\n",
       " 'play',\n",
       " 'instruct',\n",
       " 'train',\n",
       " 'tpu',\n",
       " 'main',\n",
       " 'menu',\n",
       " 'click',\n",
       " 'runtim',\n",
       " 'select',\n",
       " 'chang',\n",
       " 'runtim',\n",
       " 'type',\n",
       " 'set',\n",
       " 'tpu',\n",
       " 'hardwar',\n",
       " 'acceler',\n",
       " 'click',\n",
       " 'runtim',\n",
       " 'select',\n",
       " 'runtim',\n",
       " 'run',\n",
       " 'also',\n",
       " 'run',\n",
       " 'cell',\n",
       " 'manual',\n",
       " 'shiftent',\n",
       " 'tpu',\n",
       " 'locat',\n",
       " 'googl',\n",
       " 'cloud',\n",
       " 'optim',\n",
       " 'perform',\n",
       " 'read',\n",
       " 'data',\n",
       " 'directli',\n",
       " 'googl',\n",
       " 'cloud',\n",
       " 'storag',\n",
       " 'gc',\n",
       " 'data',\n",
       " 'model',\n",
       " 'train',\n",
       " 'exampl',\n",
       " 'train',\n",
       " 'model',\n",
       " 'combin',\n",
       " 'work',\n",
       " 'william',\n",
       " 'shakespear',\n",
       " 'use',\n",
       " 'model',\n",
       " 'compos',\n",
       " 'play',\n",
       " 'style',\n",
       " 'great',\n",
       " 'bard',\n",
       " 'love',\n",
       " 'led',\n",
       " 'dumb',\n",
       " 'lack',\n",
       " 'berjoy',\n",
       " 'face',\n",
       " 'today',\n",
       " 'spirit',\n",
       " 'roar',\n",
       " 'shame',\n",
       " 'within',\n",
       " 'power',\n",
       " 'tie',\n",
       " 'remedi',\n",
       " 'lend',\n",
       " 'occas',\n",
       " 'loud',\n",
       " 'lancast',\n",
       " 'stabb',\n",
       " 'upon',\n",
       " 'sword',\n",
       " 'ever',\n",
       " 'agripo',\n",
       " 'day',\n",
       " 'let',\n",
       " 'free',\n",
       " 'stop',\n",
       " 'word',\n",
       " 'lear',\n",
       " 'profess',\n",
       " 'hourstrang',\n",
       " 'life',\n",
       " 'sink',\n",
       " 'cri',\n",
       " 'aught',\n",
       " 'bed',\n",
       " 'seek',\n",
       " 'chast',\n",
       " 'sens',\n",
       " 'prove',\n",
       " 'burn',\n",
       " 'perforc',\n",
       " 'seen',\n",
       " 'eye',\n",
       " 'fast',\n",
       " 'download',\n",
       " 'data',\n",
       " 'download',\n",
       " 'complet',\n",
       " 'work',\n",
       " 'william',\n",
       " 'shakespear',\n",
       " 'singl',\n",
       " 'text',\n",
       " 'file',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'use',\n",
       " 'snippet',\n",
       " 'file',\n",
       " 'train',\n",
       " 'data',\n",
       " 'model',\n",
       " 'target',\n",
       " 'snippet',\n",
       " 'offset',\n",
       " 'one',\n",
       " 'charact',\n",
       " 'wget',\n",
       " 'showprogress',\n",
       " 'continu',\n",
       " 'contentshakespearetxt',\n",
       " 'http',\n",
       " 'wwwgutenbergorgfiles1001000txt',\n",
       " 'build',\n",
       " 'data',\n",
       " 'gener',\n",
       " 'import',\n",
       " 'numpi',\n",
       " 'np',\n",
       " 'import',\n",
       " 'six',\n",
       " 'import',\n",
       " 'tensorflow',\n",
       " 'tf',\n",
       " 'import',\n",
       " 'time',\n",
       " 'import',\n",
       " 'os',\n",
       " 'address',\n",
       " 'identifi',\n",
       " 'tpu',\n",
       " 'use',\n",
       " 'configur',\n",
       " 'tensorflow',\n",
       " 'tpuwork',\n",
       " 'grpc',\n",
       " 'osenviron',\n",
       " 'colabtpuaddr',\n",
       " 'shakespearetxt',\n",
       " 'contentshakespearetxt',\n",
       " 'tfloggingsetverbos',\n",
       " 'tflogginginfo',\n",
       " 'def',\n",
       " 'transform',\n",
       " 'txt',\n",
       " 'padtonon',\n",
       " 'drop',\n",
       " 'nonascii',\n",
       " 'charact',\n",
       " 'output',\n",
       " 'npasarray',\n",
       " 'ord',\n",
       " 'c',\n",
       " 'c',\n",
       " 'txt',\n",
       " 'ord',\n",
       " 'c',\n",
       " 'dtypenpint32',\n",
       " 'padto',\n",
       " 'none',\n",
       " 'output',\n",
       " 'output',\n",
       " 'padto',\n",
       " 'output',\n",
       " 'npconcaten',\n",
       " 'npzero',\n",
       " 'padto',\n",
       " 'len',\n",
       " 'txt',\n",
       " 'dtypenpint32',\n",
       " 'output',\n",
       " 'return',\n",
       " 'output',\n",
       " 'def',\n",
       " 'traininggener',\n",
       " 'seqlen100',\n",
       " 'batchsize1024',\n",
       " 'gener',\n",
       " 'yield',\n",
       " 'sourc',\n",
       " 'target',\n",
       " 'array',\n",
       " 'train',\n",
       " 'tfgfilegfil',\n",
       " 'shakespearetxt',\n",
       " 'r',\n",
       " 'f',\n",
       " 'txt',\n",
       " 'fread',\n",
       " 'tflogginginfo',\n",
       " 'input',\n",
       " 'text',\n",
       " 'len',\n",
       " 'txt',\n",
       " 'txt',\n",
       " 'sourc',\n",
       " 'transform',\n",
       " 'txt',\n",
       " 'true',\n",
       " 'offset',\n",
       " 'nprandomrandint',\n",
       " 'len',\n",
       " 'sourc',\n",
       " 'seqlen',\n",
       " 'batchsiz',\n",
       " 'model',\n",
       " 'use',\n",
       " 'spars',\n",
       " 'crossentropi',\n",
       " 'loss',\n",
       " 'kera',\n",
       " 'requir',\n",
       " 'label',\n",
       " 'rank',\n",
       " 'input',\n",
       " 'logit',\n",
       " 'add',\n",
       " 'empti',\n",
       " 'final',\n",
       " 'dimens',\n",
       " 'account',\n",
       " 'yield',\n",
       " 'npstack',\n",
       " 'sourc',\n",
       " 'idx',\n",
       " 'idx',\n",
       " 'seqlen',\n",
       " 'idx',\n",
       " 'offset',\n",
       " 'npexpanddim',\n",
       " 'npstack',\n",
       " 'sourc',\n",
       " 'idx',\n",
       " 'idx',\n",
       " 'seqlen',\n",
       " 'idx',\n",
       " 'offset',\n",
       " 'sixnext',\n",
       " 'traininggener',\n",
       " 'seqlen10',\n",
       " 'batchsize1',\n",
       " 'build',\n",
       " 'model',\n",
       " 'model',\n",
       " 'defin',\n",
       " 'twolay',\n",
       " 'forwardlstmwith',\n",
       " 'two',\n",
       " 'chang',\n",
       " 'tfkera',\n",
       " 'standard',\n",
       " 'lstm',\n",
       " 'definit',\n",
       " 'defin',\n",
       " 'input',\n",
       " 'shape',\n",
       " 'model',\n",
       " 'compli',\n",
       " 'xla',\n",
       " 'compil',\n",
       " 'static',\n",
       " 'shape',\n",
       " 'requir',\n",
       " 'use',\n",
       " 'tftrainoptim',\n",
       " 'instead',\n",
       " 'standard',\n",
       " 'kera',\n",
       " 'optim',\n",
       " 'kera',\n",
       " 'optim',\n",
       " 'support',\n",
       " 'still',\n",
       " 'experiment',\n",
       " 'embeddingdim',\n",
       " 'def',\n",
       " 'lstmmodel',\n",
       " 'seqlen100',\n",
       " 'batchsizenon',\n",
       " 'statefultru',\n",
       " 'languag',\n",
       " 'model',\n",
       " 'predict',\n",
       " 'next',\n",
       " 'word',\n",
       " 'given',\n",
       " 'current',\n",
       " 'word',\n",
       " 'sourc',\n",
       " 'tfkerasinput',\n",
       " 'namese',\n",
       " 'shape',\n",
       " 'seqlen',\n",
       " 'batchsizebatchs',\n",
       " 'dtypetfint32',\n",
       " 'embed',\n",
       " 'tfkeraslayersembed',\n",
       " 'inputdim256',\n",
       " 'outputdimembeddingdim',\n",
       " 'sourc',\n",
       " 'lstm1',\n",
       " 'tfkeraslayerslstm',\n",
       " 'embeddingdim',\n",
       " 'statefulst',\n",
       " 'returnsequencestru',\n",
       " 'embed',\n",
       " 'lstm2',\n",
       " 'tfkeraslayerslstm',\n",
       " 'embeddingdim',\n",
       " 'statefulst',\n",
       " 'returnsequencestru',\n",
       " 'lstm1',\n",
       " 'predictedchar',\n",
       " 'tfkeraslayerstimedistribut',\n",
       " 'tfkeraslayersdens',\n",
       " 'activationsoftmax',\n",
       " 'lstm2',\n",
       " 'model',\n",
       " 'tfkerasmodel',\n",
       " 'input',\n",
       " 'sourc',\n",
       " 'output',\n",
       " 'predictedchar',\n",
       " 'modelcompil',\n",
       " 'optimizertftrainrmspropoptim',\n",
       " 'learningrate001',\n",
       " 'losssparsecategoricalcrossentropi',\n",
       " 'metric',\n",
       " 'sparsecategoricalaccuraci',\n",
       " 'return',\n",
       " 'model',\n",
       " 'train',\n",
       " 'model',\n",
       " 'tfcontribtpukerastotpumodel',\n",
       " 'function',\n",
       " 'convert',\n",
       " 'tfkera',\n",
       " 'model',\n",
       " 'equival',\n",
       " 'tpu',\n",
       " 'version',\n",
       " 'use',\n",
       " 'standard',\n",
       " 'kera',\n",
       " 'method',\n",
       " 'train',\n",
       " 'fit',\n",
       " 'predict',\n",
       " 'evalu',\n",
       " 'tfkerasbackendclearsess',\n",
       " 'trainingmodel',\n",
       " 'lstmmodel',\n",
       " 'seqlen100',\n",
       " 'batchsize128',\n",
       " 'statefulfals',\n",
       " 'tpumodel',\n",
       " 'tfcontribtpukerastotpumodel',\n",
       " 'trainingmodel',\n",
       " 'strategytfcontribtputpudistributionstrategi',\n",
       " 'tfcontribclusterresolvertpuclusterresolv',\n",
       " 'tpuwork',\n",
       " 'tpumodelfitgener',\n",
       " 'traininggener',\n",
       " 'seqlen100',\n",
       " 'batchsize1024',\n",
       " 'stepsperepoch100',\n",
       " 'epochs10',\n",
       " 'tpumodelsaveweight',\n",
       " 'tmpbardh5',\n",
       " 'overwritetru',\n",
       " 'make',\n",
       " 'predict',\n",
       " 'model',\n",
       " 'use',\n",
       " 'train',\n",
       " 'model',\n",
       " 'make',\n",
       " 'predict',\n",
       " 'gener',\n",
       " 'shakespeareesqu',\n",
       " 'play',\n",
       " 'start',\n",
       " 'model',\n",
       " 'seed',\n",
       " 'sentenc',\n",
       " 'gener',\n",
       " 'charact',\n",
       " 'model',\n",
       " 'make',\n",
       " 'five',\n",
       " 'predict',\n",
       " 'initi',\n",
       " 'seed',\n",
       " 'batchsiz',\n",
       " 'predictlen',\n",
       " 'kera',\n",
       " 'requir',\n",
       " 'batch',\n",
       " 'size',\n",
       " 'specifi',\n",
       " 'ahead',\n",
       " 'time',\n",
       " 'state',\n",
       " 'model',\n",
       " 'use',\n",
       " 'sequenc',\n",
       " 'length',\n",
       " 'feed',\n",
       " 'one',\n",
       " 'charact',\n",
       " 'time',\n",
       " 'predict',\n",
       " 'next',\n",
       " 'charact',\n",
       " 'predictionmodel',\n",
       " 'lstmmodel',\n",
       " 'seqlen1',\n",
       " 'batchsizebatchs',\n",
       " 'statefultru',\n",
       " 'predictionmodelloadweight',\n",
       " 'tmpbardh5',\n",
       " 'seed',\n",
       " 'model',\n",
       " 'initi',\n",
       " 'string',\n",
       " 'copi',\n",
       " 'batchsiz',\n",
       " 'time',\n",
       " 'seedtxt',\n",
       " 'look',\n",
       " 'like',\n",
       " 'king',\n",
       " 'verili',\n",
       " 'must',\n",
       " 'go',\n",
       " 'seed',\n",
       " 'transform',\n",
       " 'seedtxt',\n",
       " 'seed',\n",
       " 'nprepeat',\n",
       " 'npexpanddim',\n",
       " 'seed',\n",
       " 'batchsiz',\n",
       " 'axis0',\n",
       " 'first',\n",
       " 'run',\n",
       " 'seed',\n",
       " 'forward',\n",
       " 'prime',\n",
       " 'state',\n",
       " 'model',\n",
       " 'predictionmodelresetst',\n",
       " 'rang',\n",
       " 'len',\n",
       " 'seedtxt',\n",
       " 'predictionmodelpredict',\n",
       " 'seed',\n",
       " 'accumul',\n",
       " 'predict',\n",
       " 'predict',\n",
       " 'seed',\n",
       " 'rang',\n",
       " 'predictlen',\n",
       " 'lastword',\n",
       " 'predict',\n",
       " 'nextprobit',\n",
       " 'predictionmodelpredict',\n",
       " 'lastword',\n",
       " 'sampl',\n",
       " 'output',\n",
       " 'distribut',\n",
       " 'nextidx',\n",
       " 'nprandomchoic',\n",
       " 'pnextprobit',\n",
       " 'rang',\n",
       " 'batchsiz',\n",
       " 'predictionsappend',\n",
       " 'npasarray',\n",
       " 'nextidx',\n",
       " 'dtypenpint32',\n",
       " 'rang',\n",
       " 'batchsiz',\n",
       " 'print',\n",
       " 'predict',\n",
       " 'dnn',\n",
       " 'p',\n",
       " 'predict',\n",
       " 'j',\n",
       " 'j',\n",
       " 'rang',\n",
       " 'predictlen',\n",
       " 'gener',\n",
       " 'join',\n",
       " 'chr',\n",
       " 'c',\n",
       " 'c',\n",
       " 'p',\n",
       " 'print',\n",
       " 'gener',\n",
       " 'print',\n",
       " 'assert',\n",
       " 'len',\n",
       " 'gener',\n",
       " 'predictlen',\n",
       " 'gener',\n",
       " 'text',\n",
       " 'short',\n",
       " 'next',\n",
       " 'learn',\n",
       " 'cloud',\n",
       " 'tpu',\n",
       " 'googl',\n",
       " 'design',\n",
       " 'optim',\n",
       " 'specif',\n",
       " 'speed',\n",
       " 'scale',\n",
       " 'ml',\n",
       " 'workload',\n",
       " 'train',\n",
       " 'infer',\n",
       " 'enabl',\n",
       " 'ml',\n",
       " 'engin',\n",
       " 'research',\n",
       " 'iter',\n",
       " 'quickli',\n",
       " 'explor',\n",
       " 'rang',\n",
       " 'cloud',\n",
       " 'tpu',\n",
       " 'tutori',\n",
       " 'colab',\n",
       " 'find',\n",
       " 'exampl',\n",
       " 'use',\n",
       " 'implement',\n",
       " 'ml',\n",
       " 'project',\n",
       " 'googl',\n",
       " 'cloud',\n",
       " 'platform',\n",
       " 'addit',\n",
       " 'gpu',\n",
       " 'tpu',\n",
       " 'avail',\n",
       " 'preconfigur',\n",
       " 'deep',\n",
       " 'learn',\n",
       " 'vm',\n",
       " 'find',\n",
       " 'automl',\n",
       " 'beta',\n",
       " 'train',\n",
       " 'custom',\n",
       " 'model',\n",
       " 'without',\n",
       " 'write',\n",
       " 'code',\n",
       " 'cloud',\n",
       " 'ml',\n",
       " 'engin',\n",
       " 'allow',\n",
       " 'run',\n",
       " 'parallel',\n",
       " 'train',\n",
       " 'hyperparamet',\n",
       " 'tune',\n",
       " 'custom',\n",
       " 'model',\n",
       " 'power',\n",
       " 'distribut',\n",
       " 'hardwar']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common words from both the files are : \n",
      "\n",
      "{'epoch', 'make', 'none', 'type', 'gener', 'googl', 'tensorflow', 'next', 'batch', 'enabl', 'specif', 'like', 'use', 'train', 'github', 'build', 'also', 'let', 'free', 'addit', 'continu', 'add', 'initi', 'sourc', 'origin', 'overview', 'start', 'deep', 'chang', 'data', 'allow', 'work', 'predict', 'given', 'time', 'click', 'feed', 'output', 'open', 'size', 'one', 'loss', 'learn', 'first'}\n"
     ]
    }
   ],
   "source": [
    "print('\\nCommon words from both the files are : \\n')\n",
    "print(set(final_web).intersection(final_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 15 Neural Network or Machine Learning related Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The top 15 technical, NN or ML related based on their frequency : \n",
      "\n",
      "('data', 6)\n",
      "('output', 6)\n",
      "('use', 5)\n",
      "('learn', 5)\n",
      "('one', 3)\n",
      "('predict', 2)\n",
      "('train', 2)\n",
      "('github', 2)\n",
      "('origin', 2)\n",
      "('also', 2)\n",
      "('work', 2)\n",
      "('sourc', 2)\n",
      "('loss', 2)\n",
      "('deep', 2)\n",
      "('overview', 1)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for i in final_text:\n",
    "        results[i] = final_web.count(i) \n",
    "\n",
    "sorted_result = sorted(results.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "print('\\nThe top 15 technical, NN or ML related based on their frequency : \\n')\n",
    "for i in range(0,15):\n",
    "    print(sorted_result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The words above with their meanings : \n",
      "\n",
      "DATA means a collection of facts from which conclusions may be drawn\n",
      "OUTPUT means final product; the things produced\n",
      "USE means the act of using\n",
      "LEARN means gain knowledge or skills\n",
      "ONE means the smallest whole number or a numeral representing this number\n",
      "PREDICT means make a prediction about; tell in advance\n",
      "TRAIN means public transport provided by a line of railway cars coupled together and drawn by a locomotive\n",
      "ORIGIN means the place where something begins, where it springs into being\n",
      "ALSO means in addition\n",
      "WORK means activity directed toward making or doing something\n",
      "LOSS means something that is lost\n",
      "DEEP means the central and most intense or profound part\n",
      "OVERVIEW means a general summary of a subject\n"
     ]
    }
   ],
   "source": [
    "print('\\nThe words above with their meanings : \\n')\n",
    "for i in range(0,15):\n",
    "    syns = wordnet.synsets(sorted_result[i][0])\n",
    "    if syns:\n",
    "        print(sorted_result[i][0].upper()+' means '+ syns[0].definition())\n",
    "    else:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
