{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('.') \n",
    "import string\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "import nltk, re, pprint\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import request\n",
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the BeautifulSoup function we scrape the html page and store it as a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://playground.tensorflow.org/\"\n",
    "response = request.urlopen(url)\n",
    "html = response.read().decode('utf8')\n",
    "web_file = BeautifulSoup(html).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nA Neural Network Playground\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTinker With a Neural Network Right Here in Your Browser.Don’t Worry, You Can’t Break It. We Promise.\\n\\n\\n\\n\\n\\n\\nreplay\\n\\n\\nplay_arrow\\npause\\n\\n\\nskip_next\\n\\n\\n\\nEpoch\\n\\n\\n\\nLearning rate\\n\\n\\n0.00001\\n0.0001\\n0.001\\n0.003\\n0.01\\n0.03\\n0.1\\n0.3\\n1\\n3\\n10\\n\\n\\n\\n\\nActivation\\n\\n\\nReLU\\nTanh\\nSigmoid\\nLinear\\n\\n\\n\\n\\nRegularization\\n\\n\\nNone\\nL1\\nL2\\n\\n\\n\\n\\nRegularization rate\\n\\n\\n0\\n0.001\\n0.003\\n0.01\\n0.03\\n0.1\\n0.3\\n1\\n3\\n10\\n\\n\\n\\n\\nProblem type\\n\\n\\nClassification\\nRegression\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nData\\n\\n\\nWhich dataset do you want to use?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRatio of training to test data:\\xa0\\xa0XX%\\n\\n\\n\\n\\n\\nNoise:\\xa0\\xa0XX\\n\\n\\n\\n\\n\\nBatch size:\\xa0\\xa0XX\\n\\n\\n\\n\\n\\n            Regenerate\\n          \\n\\n\\n\\n\\nFeatures\\nWhich properties do you want to feed in?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nClick anywhere to edit.\\nWeight/Bias is 0.2.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            This is the output from one neuron. Hover to see it larger.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            The outputs are mixed with varying weights, shown by the thickness of the lines.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\nadd\\n\\n\\nremove\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOutput\\n\\n\\nTest loss\\n\\n\\n\\nTraining loss\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Colors shows data, neuron and weight values.\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShow test data\\n\\n\\n\\nDiscretize output\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nkeyboard_arrow_down\\n\\n\\n\\n\\n\\nUm, What Is a Neural Network?\\nIt’s a technique for building a computer program that learns from data. It is based very loosely on how we think the human brain works. First, a collection of software “neurons” are created and connected together, allowing them to send messages to each other. Next, the network is asked to solve a problem, which it attempts to do over and over, each time strengthening the connections that lead to success and diminishing those that lead to failure. For a more detailed introduction to neural networks, Michael Nielsen’s Neural Networks and Deep Learning is a good place to start. For a more technical overview, try Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.\\n\\n\\nThis Is Cool, Can I Repurpose It?\\nPlease do! We’ve open sourced it on GitHub with the hope that it can make neural networks a little more accessible and easier to learn. You’re free to use it in any way that follows our Apache License. And if you have any suggestions for additions or changes, please let us know.\\nWe’ve also provided some controls below to enable you tailor the playground to a specific topic or lesson. Just choose which features you’d like to be visible below then save this link, or refresh the page.\\n\\n\\n\\nWhat Do All the Colors Mean?\\nOrange and blue are used throughout the visualization in slightly different ways, but in general orange shows negative values while blue shows positive values.\\nThe data points (represented by small circles) are initially colored orange or blue, which correspond to positive one and negative one.\\nIn the hidden layers, the lines are colored by the weights of the connections between neurons. Blue shows a positive weight, which means the network is using that output of the neuron as given. An orange line shows that the network is assiging a negative weight.\\nIn the output layer, the dots are colored orange or blue depending on their original values. The background color shows what the network is predicting for a particular area. The intensity of the color shows how confident that prediction is.\\n\\n\\nWhat Library Are You Using?\\nWe wrote a tiny neural network library\\n      that meets the demands of this educational visualization. For real-world applications, consider the\\n      TensorFlow library.\\n      \\n\\n\\nCredits\\n\\n        This was created by Daniel Smilkov and Shan Carter.\\n        This is a continuation of many people’s previous work — most notably Andrej Karpathy’s convnet.js demo\\n        and Chris Olah’s articles about neural networks.\\n        Many thanks also to D. Sculley for help with the original idea and to Fernanda Viégas and Martin Wattenberg and the rest of the\\n        Big Picture and Google Brain teams for feedback and guidance.\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSource on GitHub\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide the file into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_web = word_tokenize(web_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we remove punctuations, change the words into lowercase, remove stopwords and remove numbers from the list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_web = [''.join(char for char in strings if char not in string.punctuation) for strings in tokens_web]\n",
    "\n",
    "punc_web = [word for word in punc_web if word]\n",
    "\n",
    "lower_web = [word.lower() for word in punc_web]\n",
    "\n",
    "filtered_web = [word for word in lower_web if word not in stopwords.words('english')]\n",
    "\n",
    "no_digit_web = [x for x in filtered_web if not (x.isdigit() \n",
    "                                         or x[0] == '-' and x[1:].isdigit())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer() \n",
    "final_web = [ps.stem(word) for word in no_digit_web ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ss2.txt')\n",
    "text_file = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_text = word_tokenize(text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the same steps that we performed earlier. Remove punctuations, change the words into lowercase, remove stopwords and remove numbers from the list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_text = [''.join(char for char in strings if char not in string.punctuation) \n",
    "                   for strings in tokens_text]\n",
    "punc_text = [string for string in punc_text if string]\n",
    "lower_text = [x.lower() for x in punc_text]\n",
    "filtered_text = [word for word in lower_text if word not in stopwords.words('english')]\n",
    "no_digit_text = [x for x in filtered_text if not (x.isdigit() \n",
    "                                         or x[0] == '-' and x[1:].isdigit())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = [ps.stem(word) for word in no_digit_text ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common words from both the files are : \n",
      "\n",
      "{'epoch', 'make', 'none', 'type', 'gener', 'googl', 'tensorflow', 'next', 'batch', 'enabl', 'specif', 'like', 'use', 'train', 'github', 'build', 'also', 'let', 'free', 'addit', 'continu', 'add', 'initi', 'sourc', 'origin', 'overview', 'start', 'deep', 'chang', 'data', 'allow', 'work', 'predict', 'given', 'time', 'click', 'feed', 'output', 'open', 'size', 'one', 'loss', 'learn', 'first'}\n"
     ]
    }
   ],
   "source": [
    "print('\\nCommon words from both the files are : \\n')\n",
    "print(set(final_web).intersection(final_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 15 Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The top 15 technical, NN or ML related based on their frequency : \n",
      "\n",
      "('data', 6)\n",
      "('output', 6)\n",
      "('use', 5)\n",
      "('learn', 5)\n",
      "('one', 3)\n",
      "('predict', 2)\n",
      "('train', 2)\n",
      "('github', 2)\n",
      "('origin', 2)\n",
      "('also', 2)\n",
      "('work', 2)\n",
      "('sourc', 2)\n",
      "('loss', 2)\n",
      "('deep', 2)\n",
      "('overview', 1)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for i in final_text:\n",
    "        results[i] = final_web.count(i) \n",
    "\n",
    "sorted_result = sorted(results.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "print('\\nThe top 15 technical, NN or ML related based on their frequency : \\n')\n",
    "for i in range(0,15):\n",
    "    print(sorted_result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The words above with their meanings : \n",
      "\n",
      "DATA means a collection of facts from which conclusions may be drawn\n",
      "OUTPUT means final product; the things produced\n",
      "USE means the act of using\n",
      "LEARN means gain knowledge or skills\n",
      "ONE means the smallest whole number or a numeral representing this number\n",
      "PREDICT means make a prediction about; tell in advance\n",
      "TRAIN means public transport provided by a line of railway cars coupled together and drawn by a locomotive\n",
      "ORIGIN means the place where something begins, where it springs into being\n",
      "ALSO means in addition\n",
      "WORK means activity directed toward making or doing something\n",
      "LOSS means something that is lost\n",
      "DEEP means the central and most intense or profound part\n",
      "OVERVIEW means a general summary of a subject\n"
     ]
    }
   ],
   "source": [
    "print('\\nThe words above with their meanings : \\n')\n",
    "for i in range(0,15):\n",
    "    syns = wordnet.synsets(sorted_result[i][0])\n",
    "    if syns:\n",
    "        print(sorted_result[i][0].upper()+' means '+ syns[0].definition())\n",
    "    else:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
